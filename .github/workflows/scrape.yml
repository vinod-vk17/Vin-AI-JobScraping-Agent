name: Scrape Jobs Every 4 Hours

on:
  schedule:
    # Runs every 4 hours: 12 AM, 4 AM, 8 AM, 12 PM, 4 PM, 8 PM EST
    # EST = UTC-5, so: 5, 9, 13, 17, 21, 1 (next day)
    - cron: "0 5,9,13,17,21,1 * * *"
  workflow_dispatch:  # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Download existing database
        uses: actions/download-artifact@v4
        with:
          name: jobs-database
          path: .
        continue-on-error: true
      
      - name: Run scraper
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          DATABASE_PATH: jobs.db
        run: |
          python gemini_scraper.py
      
      - name: Upload database
        uses: actions/upload-artifact@v4
        with:
          name: jobs-database
          path: jobs.db
          retention-days: 90
